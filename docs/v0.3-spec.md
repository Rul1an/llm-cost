# v0.3 Technical Specification & Roadmap

**Status**: v0.3 implemented (dev branch)
**Release toolchain**: Zig 0.13.x (hard requirement for core/CLI)
**Project**: `llm-cost` – offline token counting & cost estimation CLI

---

## 0. Strategic Goals

### 0.1 Core Principles

1. **Strict correctness (parity)**
   Voor de ondersteunde OpenAI-encodings (`o200k_base`, `cl100k_base`) moet `llm-cost` dezelfde token-ids produceren als `tiktoken`, voor geldige UTF-8 input. Dit wordt afgedekt door:
   - Evil Corpus v2 (static JSONL)
   - Parity test-harness (`zig build test-parity`)

2. **Realistische performance**
   Niet micro-optimaliseren om de micro-optimalisatie:
   - Lineaire / log-lineaire tijd op normale én “adversarial” input.
   - Heap-based BPE-merge i.p.v. O(N²).
   - Acceptabele throughput op commodity hardware (tientallen MB/s).

3. **Robustness & safety**
   - Geen panics / UB op willekeurige bytes (inclusief invalid UTF-8).
   - Fuzzing en Evil Corpus als continue veiligheidsnetten.
   - Release pipeline met SBOM + signing.

4. **Multi-provider ready**
   - OpenAI is de eerste klasse (o200k/cl100k), maar de architectuur moet voorbereiden op extra encodings (andere vendors, open-source modellen).
   - Encodings worden via een registry en statische `EncodingSpec` aangestuurd; het systeem is voorbereid op extra vocab/bpe-binaries.

5. **Duidelijke “accuracy tiers”**
   - Niet alleen “werkt / werkt niet”, maar expliciet:
     - **Exact**: bewezen parity met referentie-tokenizer.
     - **Family**: benadering van een model-familie (bijv. “LLaMA-like”).
     - **Heuristic**: fallback zonder harde garanties.

---

## 1. Scope v0.3 – Implemented

### 1.1 Encodings

**Volledig ondersteund met parity:**

- `o200k_base` (GPT-4o familie)
  - Dedicated scanner (`o200k_scanner.zig`).
  - Fijne whitespace-regels (Branches 5–7) en contraction-suffixes.
  - Parity verified via Evil Corpus v2.

- `cl100k_base` (GPT-4 / GPT-3.5 / ada-002 familie)
  - Dedicated scanner (`cl100k_scanner.zig`) met:
    - Contractions (`'s`, `'t`, `'re`, …).
    - Letters-only words.
    - 1–3 digit number-chunks.
    - Punctuation + newline-suffix.
    - Whitespace-groepen 5–7.
  - Vocab + specials in `src/data/cl100k_base.bin` + `registry.zig`.
  - Parity verified via Evil Corpus v2.

**Heuristische fallback:**

- Voor onbekende modellen of custom namen:
  - Whitespace-based estimator.
  - Duidelijk als “approximate” gemarkeerd.

### 1.2 BPE Engine

File: `src/tokenizer/bpe.zig`

- **Zero-copy** BPE-engine:
  - `BpeEngine.init` laadt `IndexEntry[]` + string blob uit embedded `.bin`.
- **Two merge strategies**:
  - `encodeWordNaive`: O(N²), maar alleen voor korte woorden (`len < 128`).
  - `encodeWordHeap`: O(N log N), heap-based merge met doubly-linked nodes.
- **Heap-based merge details**:
  - `Node` struct (prev/next/offset/len/alive/gen).
  - `Edge` struct met:
    - `rank` (BPE-merge prioriteit)
    - `left_pos` voor deterministische tie-break (links wint).
    - generatie-velden (`left_gen`/`right_gen`) voor lazy invalidation.
  - Priority queue (`std.PriorityQueue`) met custom compare-functie.

**Resultaat v0.3:**

- `a * 4096` gaat van ~280ms → ~1.1ms (~250x sneller).
- Emoji-runs schalen nu ook ~lineair.

---

## 2. Correctness & Parity

### 2.1 Evil Corpus v2

File: `testdata/evil_corpus_v2.jsonl`
Generator: `tools/gen_evil_corpus.py`

- Geëxtraheerd via Python `tiktoken` voor:
  - `o200k_base`
  - `cl100k_base`
- Cases omvatten o.a.:
  - Contractions: `"don't"`, `"I'll"`, `" 's"`, `"foo's"`.
  - Unicode letters (accenten, niet-Latijnse scripts).
  - Digits & number-chunks: `1`, `12`, `123`, `1234`, `1234567890`.
  - Punctuation + slashes: `"!"`, `"..."`, `"////"`.
  - Whitespace varianten: `"\n"`, `"\r\n"`, `" \n "`, `"\t\n"`.
  - Lange runs: `"a"*100`, `"!"*100`.

**Eigenschappen:**

- **Frozen**: corpus staat in git, wordt niet in CI hergegenereerd.
- **Versioned**: bevat `tiktoken_version` zodat veranderingen traceerbaar zijn.

### 2.2 Parity Harness

File: `src/test/parity.zig`

- Leest JSONL-corpus.
- Voor elke entry:
  - Zoekt de `EncodingSpec` in `registry.Registry`.
  - Init `OpenAITokenizer`.
  - Encodeert de `text` en vergelijkt `expected_ids`.
- Modellen zonder vocab (hypothetisch) worden netjes geskipt.

Command:

```bash
zig build test-parity
```

Exit-criteria v0.3:
Geen mismatches op Evil Corpus v2 voor o200k_base en cl100k_base.

## 3. Robustness & Fuzzing

### 3.1 Crash/UB Fuzzing

File: `src/fuzz_test.zig`

Doel: geen panics, geen UB, stabiele error-handling.

Fuzz-targets o.a.:
- `OpenAITokenizer.count`
- `engine.estimateTokens`

Input:
willekeurige byte-sequences (incl. invalid UTF-8).

Veiligheid:
Gebruik van `SafeUtf8Iterator` in scanners om invalid UTF-8 tolerant te verwerken (fallback op byte-per-byte in plaats van panic).

Command:

```bash
zig build fuzz
```

(In CI als bounded sanity check: ~2000 iteraties per model.)

### 3.2 Unit Tests

Command:
```bash
zig build test
```

Dekken o.a.:
- Scanner-whitespace (o200k & cl100k).
- Contractions / Unicode cases.
- BPE merge (naive vs heap parity).
- Pipe CLI gedrag en foutpaden.

## 4. Performance

### 4.1 BPE Microbenchmark

File: `src/bench/bench_bpe.zig`
Command: `zig build bench-bpe`

Scenario: o200k_base, lokale dev machine.

**Worst-case scaling (ASCII):**

| Input (N) | Time (ns) | Schatting | Opmerking |
|---|---|---|---|
| 1024 | 265,710 | ~0.26 ms | baseline |
| 2048 | 555,614 | ~0.55 ms | ≈ 2.1x |
| 4096 | 1,112,658 | ~1.1 ms | ≈ 2.0x (linear) |

**Emoji-scaling (multi-byte):**

| Input (N) | Time (ns) | Schatting | Opmerking |
|---|---|---|---|
| 1024 | 936,637 | ~0.93 ms | baseline |
| 2048 | 1,548,297 | ~1.55 ms | ≈ 1.65x |
| 4096 | 3,047,118 | ~3.0 ms | ≈ 1.96x |

Conclusie v0.3:
O(N²)-gedrag is verdwenen.
Heap-merge levert lineaire / log-lineaire scaling voor stress-cases.

### 4.2 End-to-End Pipeline (Indicatief)

Scenario: `llm-cost pipe --model o200k_base`.

| Dataset | Workers | Time | Throughput | Opmerking |
|---|---|---|---|---|
| 50MB realistic | 1 | 7.07s | 7.4 MB/s | baseline single-thread |
| 50MB realistic | 10 | 0.71s | 74 MB/s | goede scaling |
| 10MB a*512 | 10 | ~0.3s | ~35 MB/s | worst-case stress scenario |

## 5. Integration & UX (Roadmap)

### 5.1 CLI ergonomie

**Roadmap v0.4:**

- Modelnamen normaliseren:
  - Ondersteun `--model openai/gpt-4o` naast `gpt-4o` (ruimte voor andere vendors).

- Accuracy-tier in output:
  - Extra veld in JSON output:
  - `"accuracy": "exact" | "family" | "heuristic"`.

- Samenvattende output:
  - `--summary`: totals over hele stream (aantal regels, totale tokens, totale cost).

### 5.2 Integratievoorbeelden

**Roadmap v0.4/v0.5:**

- Voorbeelden voor:
  - GitHub Actions (pre-flight kostencheck).
  - GitLab CI.
  - Pre-commit hook om grote commits te annoteren met token/cost-informatie.

- Optioneel:
  - Een lichte `llm-cost serve` modus (lokale HTTP API) voor interne tooling.

## 6. Multi-Encoding & Vendor Support (Roadmap)

### 6.1 Encodings-laag uitbreiden

Doel: `llm-cost` moet niet “OpenAI-only” zijn, maar OpenAI als eerste-klasse plus uitbreidbaar.

**Roadmap v0.4/v0.5:**

- **Extern vocab-formaat documenteren**:
  - Input voor `tools/convert_vocab.zig` beschrijven (token → rank, specials).
  - Helder maken hoe community eigen BPE/vocab kan toevoegen.

- **Registry uitbreiden**:
  - `EncodingSpec` blijft de kern.
  - Mogelijkheid voor:
    - extra ingebakken encodings (bijv. LLaMA/Mistral).
    - optionele “encoding packs” buiten de hoofd-binary.

- **Family-tier heuristiek**:
  - Voor modellen zonder exacte vocab:
    - encoding-type markeren (`llama-like`, `mistral-like`).
    - fallback-tokenizer kiezen die beter past dan pure whitespace.

### 6.2 Roadmap naar v0.4/v0.5

**v0.3 (nu)**
- Strict parity OpenAI (o200k_base / cl100k_base).
- BPE O(N log N).
- Evil Corpus v2 + fuzzing.
- Release pipeline met SBOM + signing.

**v0.4 – UX & Multi-provider-ready**
- CLI-UX (modelnamen, accuracy tiers, summaries).
- Documentatie voor custom vocab/encodings.
- Eerste stap naar “family-tier” tokenizers.
- CI-voorbeelden voor GitHub/GitLab.

**v0.5 – Extra encodings & long-context**
- Extra ingebouwde encodings (afhankelijk van vraag / ecosysteem).
- Optimalisaties voor zeer lange contexten (100k+ tokens, GB-scale input).
- Verdere integratie van real-world corpora in benchmarks.

## 7. Exit Criteria v0.3

Een release v0.3.0 is “done” als:

**Tests & fuzzing**
- `zig build test` → groen.
- `zig build fuzz` → geen crashes/panics.
- `zig build test-parity` → geen mismatches op Evil Corpus v2.

**Performance**
- `zig build bench-bpe` draait succesvol.
- `a * 4096` < 2ms (indicatief, afhankelijk van hardware).
- Doorvoer op realistische dataset in lijn met huidige metingen (±zelfde orde, geen grote regressies).

**Release pipeline**
- GitHub Actions Release workflow:
  - bouwt alle binaries,
  - genereert SBOM (CycloneDX via Syft),
  - signeert binaries (Cosign keyless),
  - voegt artifacts toe aan GitHub Release.

**Documentatie**
- README beschrijft:
  - ondersteunde encodings,
  - exact vs approx gedrag,
  - basis-usage en release-verificatie.
- Docs voor Evil Corpus, perf en release zijn up-to-date.

## 8. Immutable Invariants & Migration to v0.4

### 8.1 Invariants (Do Not Break)
As we move to v0.4, the following properties of the v0.3 core are **sacrosanct**:

1.  **Parity**: `o200k_base` and `cl100k_base` output **must** remain bit-identical to `tiktoken` on `Evil Corpus v2`.
2.  **Complexity**: BPE merge logic is $O(N \log N)$ (Heap-based). Naive $O(N^2)$ is purely for short-word fallback or legacy.
3.  **Performance**: `zig build bench-bpe` worst-case (e.g. `a * 4096`) must stay < 2ms on reference hardware.
4.  **Safety**: `zig build fuzz` must never panic, even with invalid UTF-8 or adversarial byte sequences.

### 8.2 Migration Notes for v0.4
Changes in v0.4 will be additive or architectural, preserving the core engine:

- **Tokenizer Semantics**: The regex scanners and BPE split behavior will **not** change.
- **CLI Contract**: Existing flags (like `--model gpt-4o`) will remain valid but may be aliased to new canonical names.
- **Output**: JSON output will gain an `accuracy` field. Downstream consumers should tolerate extra fields.

