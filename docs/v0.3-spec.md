# v0.3 Technical Specification: Performance & Completeness

**Status**: Draft
**Target version**: v0.3
**Release toolchain**: Zig 0.13.0 (core / CLI), optioneel Zig 0.14+ voor fuzz tooling
**Context**: llm-cost is een standalone CLI voor LLM-token counting en kostenraming. v0.2 bracht o200k_base-parity-infrastructuur, streaming pipe-mode en parallel workers. v0.3 focust op correctness, performance en robustness.

## 0. Strategic Goals

1.  **Strict correctness (parity)**:
    Voor de ondersteunde OpenAI-modellen (`o200k_base` / `cl100k_base`) moet `llm-cost` dezelfde tokenisering geven als `tiktoken`, op geldige UTF-8 input, geverifieerd met een “Evil Corpus” en gerichte parity-tests.

2.  **Realistische performance**:
    Geen micro-optimisatie om de micro-optimisatie. Focus op:
    *   Algoritmische efficiëntie (lineaire time, ook op “adversarial” input).
    *   Cache-locality (platte datastructuren).
    *   Allocatie-reductie.
    *   *SIMD is een optionele, experimentele bonus.*

3.  **Robustness**:
    ## Fuzzing
- **Crash Fuzzing**: Verify no panic on random byte sequences.
- **Differential Fuzzing**: Compare output against `tiktoken` (via bridge or corpus) for valid UTF-8.

## Safety & Reliability
### Invalid UTF-8
The tokenizer MUST NEVER crash on invalid UTF-8 input (fuzzing requirement).
- **Strategy**: Use `SafeUtf8Iterator` (or safe primitives) that treats invalid bytes as fallback tokens or standard replacement characters, rather than panicking.
- **Parity**: Strict parity with `tiktoken` is NOT required for invalid UTF-8, but functional stability is mandatory.

### Memory Safety
- **Bounds Checking**: All buffer accesses must be bounds-checked (Zig default).
- **Allocations**: Minimise heap allocations. Prefer `FixedBufferAllocator` or stack buffers where possible.

4.  **Supply-chain**:
    Hardening blijft op v0.2-niveau (SBOM + signing); SLSA/provenance is optioneel.

## 1. Correctness & Completeness (o200k & cl100k)

### 1.1 Scope
v0.3 richt zich op twee encodings:
*   **o200k_base** (GPT-4o familie) – reeds aanwezig in v0.2 met dedicated scanner + BPE-engine.
*   **cl100k_base** (GPT-4 familie) – wordt in v0.3 op volwaardige manier ondersteund (scanner + vocab + specials).

Voor beide geldt:
*   Pre-tokenizer is model-specifiek.
*   BPE-engine deelt dezelfde kern, maar gebruikt model-specifieke vocab/ranks/specials.
*   Special tokens en `disallowed_special` gedrag moeten matchen met `tiktoken`.

### 1.2 o200k whitespace scanning (strict behavior)
Best-effort heuristiek uit v0.2 wordt in v0.3 vervangen door een strikt gedefinieerde scanner, met gedrag dat overeenkomt met de `tiktoken`-regex voor `o200k_base`.

#### 1.2.1 Branches 5–7 (Whitespace group)
*   **Branch 5**: `\s*[\r\n]+`
*   **Branch 6**: `\s+(?!\S)`
*   **Branch 7**: `\s+`

**Gedragsvoorbeelden (o200k)**:
*   `" \n "` -> `[" \n", " "]`. Branch 5 matcht ` \n`. Branch 7 matcht ` `.
*   `"\r\n\r\n"` -> `["\r\n\r\n"]`. Branch 5 matcht de hele run.
*   `" \n\nx"` -> `[" \n\n", "x"]`. Branch 5 matcht ` \n\n`.
*   `"x \n "` -> `["x", " \n", " "]`.
*   `" \r\nx\n"` -> `[" \r\n", "x", "\n"]`.

**CRLF-constraint**:
`\r\n` en combinaties zoals `\r\n\n`, `\r\r\n` worden als één whitespace-run gezien in Branch 5, zolang er geen niet-whitespace karakter tussen zit. Geen splitting van CR/LF in aparte pre-tokens binnen één run.

#### 1.2.2 Implementatie: `o200k_scanner.zig`
Scanner blijft een dedicated struct: `O200kScanner`. Geen generieke `Scanner(Config)` in v0.3.
*   UTF-8 wordt via `std.unicode.Utf8Iterator` verwerkt.
*   Voor cp < 128 wordt eerst een ASCII-fast-path gebruikt (bitsets).
*   Priority: 1-2 (words), 3 (numbers), 4 (punctuation), 5-7 (whitespace).
    *Whitespace branches (5-7) have the LOWEST priority in the state machine.*

### 1.3 cl100k scanner
#### 1.3.1 Bron van waarheid
Regex-patterns en special-token definities worden direct uit de officiële `tiktoken` bron overgenomen.

#### 1.3.2 Implementatie: `cl100k_scanner.zig`
Nieuwe file: `src/tokenizer/cl100k_scanner.zig`.
Struct `Cl100kScanner` met dezelfde interface als `O200kScanner`.
**Gating**: `cl100k` wordt pas als volwaardig model in de CLI aangeboden (via `--model`) als vocab, scanner en specials allemaal groen licht hebben van de Evil Corpus tests.

#### 1.3.3 Specials voor cl100k
`EncodingSpec` voor cl100k wordt aangevuld met:
*   vocab-data.
*   special tokens (incl. end-of-text, FIM, chat specials).
*   aliases.

### 1.4 Special tokens
`engine.TokenizerConfig` blijft de bron voor special-beleid. Special tokens worden niet door BPE gemerged maar direct gemapt.

## 2. Robustness: Testing & Fuzzing

### 2.1 Testlagen
1.  **Unit tests**: scanner/BPE/engine.
2.  **Parity tests**: Evil Corpus + tiktoken-oracle.
3.  **Crash/UB fuzzing**: ensure no panic / UB.
4.  **Regression tests**: integratietests.

### 2.2 Evil Corpus v2 (Parity Audit)
**Doel**: `llm-cost` == `tiktoken` op geldige UTF-8.
**Script**: `tools/gen_evil_corpus.py` (Python, gepinned aan tiktoken-versie).
**Output**: Static JSONL in `testdata/evil_corpus_v2.jsonl`.
**Inhoud**:
*   Boundary cases (empty, single char, max len).
*   Unicode (emoji ZWJ/ZWNJ, RTL, diacritics).
*   Whitespace/newline variaties.
**Constraint**: Invalid UTF-8 (overlong sequences, lone surrogates, etc.) hoort **NIET** in Evil Corpus; deze cases gaan uitsluitend naar crash/UB-fuzzing.
**CI**: `zig build test-parity`. Geen Python runtime in CI.

### 2.3 Crash/UB fuzzing
**Doel**: Geen panics, geen UB.
**Target**: `engine.estimateTokens`.
**Input**: Random bytes (valid + invalid).
**Tooling**: `std.testing.fuzz` (Zig 0.14+ allowed). Dedicated fuzz workflow.
**Scope**: Fuzz-harness en fuzz-build zijn **geen** onderdeel van de release-build; het is een aparte CI workflow die een eigen Zig-versie mag gebruiken.
**Invariants**: Elke door fuzzing gevonden bug wordt gereproduceerd in een gerichte regression-test om de fix te borgen.

## 3. Performance: Realistic Optimization

### 3.1 Benchmark-specificatie
**Scenario A (Single-thread)**:
*   `llm-cost pipe --model gpt-4o --field text --mode tokens --workers 1`
*   Input: 100MB NDJSON.
*   Target: >10x sneller dan v0.2 baseline.

**Scenario B (Multi-thread)**:
*   `--workers N` (N = aantal logische cores op testmachine).
*   Metric: Scaling factor t.o.v. scenario A.
*   Target: Aantoonbare scaling (geen regressie), geen hard MB/s target.

### 3.2 Optimalisatieprioriteiten
1.  **Datastructuren (High)**: Flatten BPE rank map (contiguous arrays, O(1) pointer chase).
    *   **Doel**: Empirisch lineair gedrag op adversarial inputs (`a`*N, emoji-runs, etc.). Absolute worst-case guarantees minder belangrijk dan lineaire scaling in praktijk.
2.  **Allocaties (High)**: Arenas, fixed buffers in hot loop.
3.  **ASCII fast-path**: 128-bit bitsets.
4.  **SIMD (Experimental)**: Alleen mergen als >20% speedup.

## 4. Deliverables & Exit Criteria v0.3
*   **Parity**: Evil Corpus tests groen voor o200k/cl100k.
*   **Performance**: Scenario A >10x baseline (~9 MB/s).
*   **Robustness**: Fuzz job draait stabiel.
*   **Release**: Binaries, SBOM, Cosign signatures.
